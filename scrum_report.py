#!/usr/bin/env python3
"""
JIRA í‹°ì¼“ì„ ë¶„ì„í•˜ì—¬ Confluence ìœ„í‚¤ì— ìŠ¤í¬ëŸ¼ ë³´ê³ ì„œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import os
import json
import requests
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
JIRA_EMAIL = os.environ.get('JIRA_EMAIL')
JIRA_TOKEN = os.environ.get('JIRA_TOKEN')
WIKI_PARENT_PAGE_ID = os.environ.get('WIKI_PARENT_PAGE_ID', '291243949')

JIRA_BASE_URL = "https://musinsa-oneteam.atlassian.net"
WIKI_BASE_URL = f"{JIRA_BASE_URL}/wiki"

# ë‚ ì§œ ì •ë³´
TODAY = datetime.now().strftime('%Y-%m-%d')
MONTH = datetime.now().strftime('%Y-%m')
YEAR = datetime.now().strftime('%Y')
MONTH_NUM = datetime.now().strftime('%m')

print(f"ğŸ“… ë‚ ì§œ: {TODAY}")
print(f"ğŸ“ ì›”: {MONTH}")

def api_request(method, url, json_data=None):
    """API ìš”ì²­ í—¬í¼ í•¨ìˆ˜"""
    auth = (JIRA_EMAIL, JIRA_TOKEN)
    headers = {"Content-Type": "application/json"}

    if method == "GET":
        response = requests.get(url, auth=auth, headers=headers)
    elif method == "POST":
        response = requests.post(url, auth=auth, headers=headers, json=json_data)
    else:
        raise ValueError(f"Unsupported method: {method}")

    return response.json()

def get_jira_tickets():
    """JIRA í‹°ì¼“ ì¡°íšŒ"""
    print("ğŸ” JIRA í‹°ì¼“ ì¡°íšŒ ì¤‘...")

    jql = "assignee=currentUser() AND updated>=-7d ORDER BY updated DESC"
    url = f"{JIRA_BASE_URL}/rest/api/3/search/jql"
    params = f"?jql={requests.utils.quote(jql)}&maxResults=50&fields=summary,status,description,updated,created,comment"

    response = api_request("GET", url + params)

    print(f"  âœ… {len(response.get('issues', []))}ê°œ í‹°ì¼“ ì¡°íšŒë¨")
    return response.get('issues', [])

def get_confluence_pages():
    """Confluence í˜ì´ì§€ ì¡°íšŒ"""
    print("ğŸ“„ Confluence í˜ì´ì§€ ì¡°íšŒ ì¤‘...")

    # ìµœê·¼ 7ì¼ê°„ ìƒì„±/ìˆ˜ì •í•œ í˜ì´ì§€ ì¡°íšŒ
    cql = "contributor=currentUser() AND lastModified >= now('-7d') ORDER BY lastModified DESC"
    url = f"{WIKI_BASE_URL}/rest/api/content/search"
    params = f"?cql={requests.utils.quote(cql)}&limit=20&expand=history"

    response = api_request("GET", url + params)

    print(f"  âœ… {len(response.get('results', []))}ê°œ í˜ì´ì§€ ì¡°íšŒë¨")
    return response.get('results', [])

def analyze_tickets(issues, pages=[]):
    """í‹°ì¼“ ë° Confluence í˜ì´ì§€ ë¶„ì„ ë° ë¶„ë¥˜"""
    print("ğŸ“Š í‹°ì¼“ ë¶„ì„ ì¤‘...")

    in_progress = []
    ktlo_items = []

    # Confluence í˜ì´ì§€ ì²˜ë¦¬
    for page in pages:
        page_id = page['id']
        title = page['title']

        # ìë™ ìƒì„±ëœ ìŠ¤í¬ëŸ¼ ë³´ê³ ì„œ í˜ì´ì§€ëŠ” ì œì™¸
        if title.startswith('202') and len(title) == 10:  # YYYY-MM-DD í˜•ì‹
            continue

        # ì—…ë°ì´íŠ¸ ë‚ ì§œ ì¶”ì¶œ (ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        try:
            if 'history' in page and 'lastUpdated' in page['history']:
                updated = page['history']['lastUpdated']['when'][:10]
            elif 'lastModified' in page:
                updated = page['lastModified'][:10]
            else:
                updated = TODAY
        except:
            updated = TODAY

        page_url = f"{WIKI_BASE_URL}{page['_links']['webui']}"

        item = {
            'key': f'WIKI-{page_id}',
            'summary': f'ğŸ“„ {title}',
            'status': 'Wiki',
            'updated': updated,
            'url': page_url,
            'comment': None
        }
        in_progress.append(item)

    # JIRA í‹°ì¼“ ì²˜ë¦¬
    for issue in issues:
        key = issue['key']
        summary = issue['fields']['summary']
        status = issue['fields']['status']['name']
        updated = issue['fields']['updated'][:10]

        # ëŒ“ê¸€ ì¶”ì¶œ
        comments = issue['fields'].get('comment', {}).get('comments', [])
        recent_comment = None

        if comments:
            last_comment = comments[-1]
            author = last_comment['author']['displayName']
            created = last_comment['created'][:10]
            body_text = ''

            if 'body' in last_comment:
                body = last_comment['body']
                if isinstance(body, dict) and 'content' in body:
                    for content in body['content']:
                        if content.get('type') == 'paragraph' and 'content' in content:
                            for text_node in content['content']:
                                if text_node.get('type') == 'text':
                                    body_text += text_node.get('text', '')

            if body_text and 'ìë™ë©”ì‹œì§€' not in body_text:
                recent_comment = {
                    'author': author.split('/')[0],
                    'date': created,
                    'text': body_text[:150]
                }

        item = {
            'key': key,
            'summary': summary,
            'status': status,
            'updated': updated,
            'comment': recent_comment
        }

        # ë¶„ë¥˜
        if status in ['In Progress', 'SUGGESTED']:
            in_progress.append(item)
        elif status == 'ì™„ë£Œ' and any(word in summary for word in ['í™•ì¸', 'ë¬¸ì˜', 'ë°ì´í„°', 'ìš”ì²­']):
            ktlo_items.append(item)

    print(f"  âœ… ì§„í–‰ì¤‘: {len(in_progress)}ê°œ, KTLO: {len(ktlo_items)}ê°œ")
    return in_progress, ktlo_items

def generate_html(in_progress, ktlo_items):
    """HTML ì½˜í…ì¸  ìƒì„± - í‘œ í˜•ì‹"""
    # ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼ ê³„ì‚°
    from datetime import timedelta
    today = datetime.now()
    days_until_friday = (4 - today.weekday()) % 7
    if days_until_friday == 0:
        days_until_friday = 7
    next_friday = today + timedelta(days=days_until_friday)
    target_date = next_friday.strftime('~%m/%d')

    # HTML ì‹œì‘
    html = '<h1>ì–´ì œ ì˜¨ì½œ ì´ìŠˆ</h1><p><br /></p><hr />'
    html += '<table data-layout="center"><colgroup>'
    html += '<col style="width: 80px;" />'
    html += '<col style="width: 400px;" />'
    html += '<col style="width: 300px;" />'
    html += '<col style="width: 250px;" />'
    html += '<col style="width: 300px;" />'
    html += '</colgroup><tbody>'

    # í—¤ë”
    html += '<tr>'
    html += '<th><p><strong>ì´ë¦„</strong></p></th>'
    html += '<th><p><strong>ê³¼ì œ</strong></p></th>'
    html += f'<th><p><strong>{target_date} ëª©í‘œ</strong></p></th>'
    html += '<th><p><strong>ì´ìŠˆ</strong></p></th>'
    html += '<th><p><strong>KTLO</strong></p></th>'
    html += '</tr>'

    # ìµœí˜•ìˆ˜ í–‰
    html += '<tr>'
    html += '<td><p>ìµœí˜•ìˆ˜</p></td>'

    # ê³¼ì œ (ì§„í–‰ì¤‘)
    html += '<td><ul>'
    if not in_progress:
        html += '<li><p><em>ì§„í–‰ì¤‘ì¸ ê³¼ì œê°€ ì—†ìŠµë‹ˆë‹¤.</em></p></li>'
    else:
        for item in in_progress:
            # URL ê²°ì • (Confluence í˜ì´ì§€ë©´ url í•„ë“œ ì‚¬ìš©, ì•„ë‹ˆë©´ JIRA ë§í¬)
            if 'url' in item:
                link_url = item['url']
                link_text = item['summary']
            else:
                link_url = f"https://jira.team.musinsa.com/browse/{item['key']}"
                link_text = f"{item['key']}: {item['summary']}"

            html += f'<li><p><a href="{link_url}">{link_text}</a></p>'
            if item.get('comment'):
                html += f'<ul><li><p><em>[{item["comment"]["date"]}] {item["comment"]["author"]}: {item["comment"]["text"]}</em></p></li></ul>'
            html += '</li>'
    html += '</ul><p><br /></p></td>'

    # ëª©í‘œ (ë¹ˆì¹¸)
    html += '<td><p><br /></p></td>'

    # ì´ìŠˆ (ë¹ˆì¹¸)
    html += '<td><p><br /></p></td>'

    # KTLO
    html += '<td><ul>'
    if not ktlo_items:
        html += '<li><p><em>ì™„ë£Œëœ KTLOê°€ ì—†ìŠµë‹ˆë‹¤.</em></p></li>'
    else:
        for item in ktlo_items[:15]:
            html += f'<li><p><a href="https://jira.team.musinsa.com/browse/{item["key"]}">{item["key"]}</a>: {item["summary"]} <em>({item["updated"]})</em></p></li>'
    html += '</ul></td>'

    html += '</tr>'
    html += '</tbody></table>'
    html += '<p><br /></p>'

    return html

def get_or_create_month_page():
    """ì›”ë³„ í˜ì´ì§€ í™•ì¸ ë° ìƒì„±"""
    print("ğŸ“‚ ì›”ë³„ í˜ì´ì§€ í™•ì¸ ì¤‘...")

    # ìì‹ í˜ì´ì§€ ì¡°íšŒ
    url = f"{WIKI_BASE_URL}/rest/api/content/{WIKI_PARENT_PAGE_ID}/child/page"
    response = api_request("GET", url)

    # ì´ë²ˆ ë‹¬ í˜ì´ì§€ ì°¾ê¸°
    for page in response.get('results', []):
        if page['title'] == MONTH:
            print(f"  âœ… ì›”ë³„ í˜ì´ì§€ ì¡´ì¬: ID={page['id']}")
            return page['id']

    # ì—†ìœ¼ë©´ ìƒì„±
    print(f"  â†’ ì›”ë³„ í˜ì´ì§€ ìƒì„± ì¤‘: {MONTH}")

    page_data = {
        "type": "page",
        "title": MONTH,
        "space": {"key": "~hschoi82"},
        "ancestors": [{"id": WIKI_PARENT_PAGE_ID}],
        "body": {
            "storage": {
                "value": f"<p>{YEAR}ë…„ {MONTH_NUM}ì›” ìŠ¤í¬ëŸ¼ ë³´ê³ ì„œ</p>",
                "representation": "storage"
            }
        }
    }

    url = f"{WIKI_BASE_URL}/rest/api/content"
    response = api_request("POST", url, page_data)

    if 'id' in response:
        print(f"  âœ… ì›”ë³„ í˜ì´ì§€ ìƒì„± ì™„ë£Œ: ID={response['id']}")
        return response['id']
    else:
        print(f"  âŒ ì›”ë³„ í˜ì´ì§€ ìƒì„± ì‹¤íŒ¨: {response}")
        exit(1)

def create_daily_page(month_page_id, html_content):
    """ì¼ìë³„ í˜ì´ì§€ ìƒì„±"""
    print(f"ğŸ“„ ì¼ìë³„ í˜ì´ì§€ ìƒì„± ì¤‘: {TODAY}")

    page_data = {
        "type": "page",
        "title": TODAY,
        "space": {"key": "~hschoi82"},
        "ancestors": [{"id": month_page_id}],
        "body": {
            "storage": {
                "value": html_content,
                "representation": "storage"
            }
        }
    }

    url = f"{WIKI_BASE_URL}/rest/api/content"

    try:
        response = api_request("POST", url, page_data)

        if 'id' in response:
            page_url = f"{response['_links']['base']}{response['_links']['webui']}"
            print(f"  âœ… í˜ì´ì§€ ìƒì„± ì™„ë£Œ!")
            print(f"  ğŸ”— {page_url}")
            return page_url
        else:
            print(f"  âŒ í˜ì´ì§€ ìƒì„± ì‹¤íŒ¨: {response}")
            return None
    except Exception as e:
        print(f"  âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        return None

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 80)
    print("ğŸš€ ìŠ¤í¬ëŸ¼ ë³´ê³ ì„œ ìë™ ìƒì„± ì‹œì‘")
    print("=" * 80)
    print()

    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    if not JIRA_EMAIL or not JIRA_TOKEN:
        print("âŒ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   JIRA_EMAILê³¼ JIRA_TOKENì„ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        exit(1)

    # 1. JIRA í‹°ì¼“ ì¡°íšŒ
    issues = get_jira_tickets()

    # 2. Confluence í˜ì´ì§€ ì¡°íšŒ
    pages = get_confluence_pages()

    # 3. í‹°ì¼“ ë° í˜ì´ì§€ ë¶„ì„
    in_progress, ktlo_items = analyze_tickets(issues, pages)

    # 4. HTML ìƒì„±
    html_content = generate_html(in_progress, ktlo_items)

    # 5. ì›”ë³„ í˜ì´ì§€ í™•ì¸/ìƒì„±
    month_page_id = get_or_create_month_page()

    # 6. ì¼ìë³„ í˜ì´ì§€ ìƒì„±
    page_url = create_daily_page(month_page_id, html_content)

    print()
    print("=" * 80)
    if page_url:
        print("âœ… ìŠ¤í¬ëŸ¼ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ”— {page_url}")
    else:
        print("âŒ ìŠ¤í¬ëŸ¼ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨")
    print("=" * 80)

if __name__ == "__main__":
    main()
